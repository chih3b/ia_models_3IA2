{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"collapsed_sections":["NfIJMopstsYw","dmaGYRr4bve_","PaSx9UV5wtWx"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# YOLOv8 Installation","metadata":{"id":"VQmdArW-p4jg"}},{"cell_type":"code","source":"# Create YOLOv8 root folder\n!mkdir yolov8-architecture","metadata":{"id":"KP_NYNiPqAJz","execution":{"iopub.status.busy":"2025-04-24T19:59:03.151859Z","iopub.execute_input":"2025-04-24T19:59:03.152209Z","iopub.status.idle":"2025-04-24T19:59:04.252132Z","shell.execute_reply.started":"2025-04-24T19:59:03.152178Z","shell.execute_reply":"2025-04-24T19:59:04.250914Z"},"trusted":true},"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'yolov8-architecture': File exists\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Go to YOLOv8 root folder\n%cd yolov8-architecture","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EwAstpt-qDT8","outputId":"118a88c3-548d-4bb0-ee1f-fc4f76d1eeb8","execution":{"iopub.status.busy":"2025-04-24T20:00:01.996276Z","iopub.execute_input":"2025-04-24T20:00:01.996649Z","iopub.status.idle":"2025-04-24T20:00:02.003644Z","shell.execute_reply.started":"2025-04-24T20:00:01.996622Z","shell.execute_reply":"2025-04-24T20:00:02.002583Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/yolov8-architecture\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Install YOLOv8\n!pip install ultralytics==8.0.196\n\nimport ultralytics\nultralytics.checks()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DcHWS3mfqFnJ","outputId":"c844387f-99be-49fd-a003-8845526126fa","execution":{"iopub.status.busy":"2025-04-24T20:00:37.452423Z","iopub.execute_input":"2025-04-24T20:00:37.452791Z","iopub.status.idle":"2025-04-24T20:01:08.636779Z","shell.execute_reply.started":"2025-04-24T20:00:37.452764Z","shell.execute_reply":"2025-04-24T20:01:08.635835Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Ultralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 6277.6/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Download the YOLOv8 Architecture File\n!wget https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/models/v8/yolov8.yaml","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3AuK-mnsJhP","outputId":"48f7dae0-8456-469f-bb8d-0d9f4df42142","execution":{"iopub.status.busy":"2025-04-24T20:01:19.712952Z","iopub.execute_input":"2025-04-24T20:01:19.713577Z","iopub.status.idle":"2025-04-24T20:01:21.023509Z","shell.execute_reply.started":"2025-04-24T20:01:19.713539Z","shell.execute_reply":"2025-04-24T20:01:21.022549Z"},"trusted":true},"outputs":[{"name":"stdout","text":"--2025-04-24 20:01:20--  https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/models/v8/yolov8.yaml\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1977 (1.9K) [text/plain]\nSaving to: 'yolov8.yaml'\n\nyolov8.yaml         100%[===================>]   1.93K  --.-KB/s    in 0s      \n\n2025-04-24 20:01:20 (27.2 MB/s) - 'yolov8.yaml' saved [1977/1977]\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# YOLOv8 Architecture","metadata":{"id":"CyZYHyZZqIlY"}},{"cell_type":"markdown","source":"<div>\n  <img src=\"https://www.stunningvisionai.com/course/yolov8-architecture.png\" height=\"750\"/>\n</div>","metadata":{"id":"LutYYwPWgXjc"}},{"cell_type":"code","source":"# Create YOLOv8l Architecture\n!cp yolov8.yaml yolov8m.yaml","metadata":{"id":"ZlblfRfkD6kP","execution":{"iopub.status.busy":"2025-04-24T20:01:30.816816Z","iopub.execute_input":"2025-04-24T20:01:30.817573Z","iopub.status.idle":"2025-04-24T20:01:31.948077Z","shell.execute_reply.started":"2025-04-24T20:01:30.817540Z","shell.execute_reply":"2025-04-24T20:01:31.946660Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Modified YOLOv8 Architecture for Small Objects","metadata":{"id":"NfIJMopstsYw"}},{"cell_type":"code","source":"# Copy YOLOv8l Small Architecture\n!cp yolov8.yaml yolov8l-small.yaml","metadata":{"id":"DYt_pPSGscWq","execution":{"iopub.status.busy":"2025-02-26T14:39:32.156967Z","iopub.execute_input":"2025-02-26T14:39:32.157339Z","iopub.status.idle":"2025-02-26T14:39:33.165242Z","shell.execute_reply.started":"2025-02-26T14:39:32.157309Z","shell.execute_reply":"2025-02-26T14:39:33.163918Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"<div>\n  <img src=\"https://www.stunningvisionai.com/course/yolov8-architecture-modification-for-small-object.png\" height=\"685\"/>\n</div>","metadata":{"id":"7V0toB1Nvo7a"}},{"cell_type":"markdown","source":"<div>\n  <img src=\"https://www.stunningvisionai.com/course/yolov8-architecture-for-small-object.png\" height=\"692\"/>\n</div>","metadata":{"id":"8VwkaWFwvvw4"}},{"cell_type":"markdown","source":"### Training a Modified Model (Small Objects)","metadata":{"id":"U5Br0L9QwM_O"}},{"cell_type":"code","source":"# Training a Modified Model (Small Objects)\n!yolo detect train model=yolov8l-small.yaml data=data/sperm.yaml workers=2 batch=12 device=0 epochs=100 patience=50 name=yolov8_sperm_small","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hAddduSiwOo4","outputId":"ec4226cf-f6a9-45e6-fb48-54ef5c3793ad"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modified YOLOv8 Architecture for Medium Objects","metadata":{"id":"PaSx9UV5wtWx"}},{"cell_type":"code","source":"# Copy YOLOv8l Medium Architecture\n!cp yolov8.yaml yolov8m-medium.yaml","metadata":{"id":"TWCNEGT5b6Fn","execution":{"iopub.status.busy":"2025-04-24T20:01:44.940200Z","iopub.execute_input":"2025-04-24T20:01:44.940611Z","iopub.status.idle":"2025-04-24T20:01:46.066066Z","shell.execute_reply.started":"2025-04-24T20:01:44.940579Z","shell.execute_reply":"2025-04-24T20:01:46.064618Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"<div>\n  <img src=\"https://www.stunningvisionai.com/course/yolov8-architecture-modification-for-medium-object.png\" height=\"685\"/>\n</div>","metadata":{"id":"gb8_oRkoz_rN"}},{"cell_type":"markdown","source":"<div>\n  <img src=\"https://www.stunningvisionai.com/course/yolov8-architecture-for-medium-object.png\" height=\"685\"/>\n</div>","metadata":{"id":"aXpeCgn10Cei"}},{"cell_type":"markdown","source":"### Training a Modified Model (Medium Objects)","metadata":{"id":"7FbhesFs0Yt6"}},{"cell_type":"code","source":"%%writefile /kaggle/working/yolov8-architecture/yolov8m-medium.yaml\n# Ultralytics YOLO 🚀, AGPL-3.0 license\n# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect\n\n# Parameters\nnc: 80 # number of classes\n#scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'\n  # [depth, width, max_channels]\n  #n: [0.33, 0.25, 1024] # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs\n  #s: [0.33, 0.50, 1024] # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs\n # m: [0.67, 0.75, 768] # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs\n # l: [1.00, 1.00, 512] # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n  #x: [1.00, 1.25, 512] # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs\n\ndepth_multiple: 0.67\nwidth_multiple: 0.75\nmax_channels: 768\n# YOLOv8.0n backbone\nbackbone:\n  # [from, repeats, module, args]\n  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\n  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\n  - [-1, 3, C2f, [128, True]]\n  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8\n  - [-1, 6, C2f, [256, True]]\n  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16\n  - [-1, 6, C2f, [512, True]]\n  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\n  - [-1, 3, C2f, [1024, True]]\n  - [-1, 1, SPPF, [1024, 5]] # 9\n\n# YOLOv8.0n head\nhead:\n  - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n  - [[-1, 6], 1, Concat, [1]] # cat backbone P4\n  - [-1, 3, C2f, [512]] # 12\n\n  #- [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n  #- [[-1, 4], 1, Concat, [1]] # cat backbone P3\n  #- [-1, 3, C2f, [256]] # 15 (P3/8-small)\n\n  - [4, 1, Conv, [256, 3, 2]]\n  - [[-1, 12], 1, Concat, [1]] # cat head P4\n  - [-1, 3, C2f, [512]] # 18 (P4/16-medium) -> 15\n\n # - [-1, 1, Conv, [512, 3, 2]]\n  #- [[-1, 9], 1, Concat, [1]] # cat head P5\n # - [-1, 3, C2f, [1024]] # 21 (P5/32-large)\n\n  - [[15], 1, Detect, [nc]] # Detect(P3, P4, P5)","metadata":{"execution":{"iopub.status.busy":"2025-04-24T20:01:53.014764Z","iopub.execute_input":"2025-04-24T20:01:53.015402Z","iopub.status.idle":"2025-04-24T20:01:53.022229Z","shell.execute_reply.started":"2025-04-24T20:01:53.015373Z","shell.execute_reply":"2025-04-24T20:01:53.021273Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/yolov8-architecture/yolov8m-medium.yaml\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"GKR5d1Hy1bW1WBLrIg0Z\")\nproject = rf.workspace(\"phone-1nwp8\").project(\"phone-detect-xqya5\")\nversion = project.version(36)\ndataset = version.download(\"yolov8\")\n                ","metadata":{"execution":{"iopub.status.busy":"2025-04-24T20:02:00.233740Z","iopub.execute_input":"2025-04-24T20:02:00.234077Z","iopub.status.idle":"2025-04-24T20:02:25.221341Z","shell.execute_reply.started":"2025-04-24T20:02:00.234052Z","shell.execute_reply":"2025-04-24T20:02:25.220219Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting roboflow\n  Downloading roboflow-1.1.61-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from roboflow) (2024.7.4)\nCollecting idna==3.7 (from roboflow)\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: cycler in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.5)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.4)\nRequirement already satisfied: opencv-python-headless==4.10.0.84 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (9.5.0)\nCollecting pillow-heif>=0.18.0 (from roboflow)\n  Downloading pillow_heif-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.32.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\nRequirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.4)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.1)\nRequirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\nCollecting filetype (from roboflow)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nCollecting Pillow>=7.1.2 (from roboflow)\n  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.47.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\nDownloading roboflow-1.1.61-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow_heif-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nInstalling collected packages: filetype, Pillow, idna, pillow-heif, roboflow\n  Attempting uninstall: Pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: idna\n    Found existing installation: idna 3.6\n    Uninstalling idna-3.6:\n      Successfully uninstalled idna-3.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-10.4.0 filetype-1.2.0 idna-3.7 pillow-heif-0.22.0 roboflow-1.1.61\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in Phone-detect-36 to yolov8:: 100%|██████████| 434557/434557 [00:06<00:00, 68116.00it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to Phone-detect-36 in yolov8:: 100%|██████████| 18888/18888 [00:02<00:00, 7096.45it/s]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import yaml\n\n# Path to your data.yaml file\nyaml_path = '/kaggle/working/yolov8-architecture/Phone-detect-36/data.yaml'\n\n# Load the yaml file\nwith open(yaml_path, 'r') as file:\n    data_config = yaml.safe_load(file)\n\n# Print the current configuration to see what needs to be changed\nprint(data_config)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-24T20:02:42.554140Z","iopub.execute_input":"2025-04-24T20:02:42.554533Z","iopub.status.idle":"2025-04-24T20:02:42.562152Z","shell.execute_reply.started":"2025-04-24T20:02:42.554476Z","shell.execute_reply":"2025-04-24T20:02:42.561177Z"},"trusted":true},"outputs":[{"name":"stdout","text":"{'names': ['0'], 'nc': 1, 'roboflow': {'license': 'CC BY 4.0', 'project': 'phone-detect-xqya5', 'url': 'https://universe.roboflow.com/phone-1nwp8/phone-detect-xqya5/dataset/36', 'version': 36, 'workspace': 'phone-1nwp8'}, 'test': 'test/images', 'train': 'train/images', 'val': 'valid/images'}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Modify the paths to the train and validation images\ndata_config['train'] = '/kaggle/working/yolov8-architecture/Phone-detect-36/train/images'\ndata_config['val'] = '/kaggle/working/yolov8-architecture/Phone-detect-36/valid/images'\ndata_config['test'] = '/kaggle/working/yolov8-architecture/Phone-detect-36/test/images'\n\n# If there are other paths that need to be updated, modify them here as well\n# e.g., data_config['test'] = 'path/to/test/images'\n\n# Print the updated configuration to verify changes\nprint(data_config)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-24T20:02:45.478706Z","iopub.execute_input":"2025-04-24T20:02:45.479323Z","iopub.status.idle":"2025-04-24T20:02:45.484550Z","shell.execute_reply.started":"2025-04-24T20:02:45.479294Z","shell.execute_reply":"2025-04-24T20:02:45.483563Z"},"trusted":true},"outputs":[{"name":"stdout","text":"{'names': ['0'], 'nc': 1, 'roboflow': {'license': 'CC BY 4.0', 'project': 'phone-detect-xqya5', 'url': 'https://universe.roboflow.com/phone-1nwp8/phone-detect-xqya5/dataset/36', 'version': 36, 'workspace': 'phone-1nwp8'}, 'test': '/kaggle/working/yolov8-architecture/Phone-detect-36/test/images', 'train': '/kaggle/working/yolov8-architecture/Phone-detect-36/train/images', 'val': '/kaggle/working/yolov8-architecture/Phone-detect-36/valid/images'}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Save the updated yaml file\nwith open(yaml_path, 'w') as file:\n    yaml.safe_dump(data_config, file)\n\nprint(f\"Updated data.yaml successfully!\")\n","metadata":{"execution":{"iopub.status.busy":"2025-04-24T20:02:48.659338Z","iopub.execute_input":"2025-04-24T20:02:48.660089Z","iopub.status.idle":"2025-04-24T20:02:48.667623Z","shell.execute_reply.started":"2025-04-24T20:02:48.660059Z","shell.execute_reply":"2025-04-24T20:02:48.666575Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Updated data.yaml successfully!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Training a Modified Model (Medium Objects)\n!yolo task=detect mode=train model=/kaggle/working/yolov8-architecture/yolov8m-medium.yaml data=/kaggle/working/yolov8-architecture/Phone-detect-36/data.yaml  batch=-1 device=0 epochs=40 patience=50 name=yolov8_phone","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:02:51.187865Z","iopub.execute_input":"2025-04-24T20:02:51.188435Z","iopub.status.idle":"2025-04-24T22:32:39.479475Z","shell.execute_reply.started":"2025-04-24T20:02:51.188407Z","shell.execute_reply":"2025-04-24T22:32:39.478546Z"}},"outputs":[{"name":"stdout","text":"\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   2067456  ultralytics.nn.modules.block.C2f             [1152, 384, 2]                \n 13                   4  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 14            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 16                [15]  1   3107872  ultralytics.nn.modules.head.Detect           [80, [384]]                   \nYOLOv8m-medium summary: 213 layers, 23617360 parameters, 23617344 gradients, 65.8 GFLOPs\n\nNew https://pypi.org/project/ultralytics/8.3.115 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/yolov8-architecture/yolov8m-medium.yaml, data=/kaggle/working/yolov8-architecture/Phone-detect-36/data.yaml, epochs=40, patience=50, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=yolov8_phone, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8_phone\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 16.0MB/s]\n2025-04-24 20:03:07.197555: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-24 20:03:07.197723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-24 20:03:07.335421: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   2067456  ultralytics.nn.modules.block.C2f             [1152, 384, 2]                \n 13                   4  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 14            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 16                [15]  1   3077457  ultralytics.nn.modules.head.Detect           [1, [384]]                    \nYOLOv8m-medium summary: 213 layers, 23586945 parameters, 23586929 gradients, 65.7 GFLOPs\n\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8_phone', view at http://localhost:6006/\nFreezing layer 'model.16.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n100%|██████████████████████████████████████| 6.23M/6.23M [00:00<00:00, 81.0MB/s]\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.24G reserved, 0.22G allocated, 15.42G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    23586945       65.75         0.608         31.21         68.38        (1, 3, 640, 640)                    list\n    23586945       131.5         0.879            25         50.79        (2, 3, 640, 640)                    list\n    23586945         263         1.845         41.71         88.43        (4, 3, 640, 640)                    list\n    23586945         526         3.053         77.74         106.4        (8, 3, 640, 640)                    list\n    23586945        1052         5.486         135.7         169.2       (16, 3, 640, 640)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 27 for CUDA:0 9.60G/15.89G (60%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov8-architecture/Phone-detect-36/train/labels\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov8-architecture/Phone-detect-36/train/labels.cache\nWARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 109, len(boxes) = 8402. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov8-architecture/Phone-detect-36/valid/labels..\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov8-architecture/Phone-detect-36/valid/labels.cache\nWARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 16, len(boxes) = 1874. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nPlotting labels to runs/detect/yolov8_phone/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 56 weight(decay=0.0), 59 weight(decay=0.000421875), 58 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/yolov8_phone\u001b[0m\nStarting training for 40 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/40      11.2G      3.271      3.071       3.43         50        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.119      0.123     0.0342     0.0119\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/40      11.3G      2.102      2.168      2.294         50        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.296      0.161       0.14     0.0598\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/40      11.4G      1.825      1.777      1.977         47        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.205       0.25      0.133     0.0583\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/40      11.4G      1.651      1.529       1.81         40        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.514      0.382      0.357       0.16\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/40      11.4G      1.505      1.306      1.661         46        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.362      0.359       0.31      0.157\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/40      11.4G      1.452      1.205      1.614         45        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.351      0.334      0.252      0.135\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/40      11.4G      1.376      1.112      1.564         50        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874       0.56       0.54      0.547      0.302\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/40      11.4G      1.335       1.04      1.517         47        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.692      0.498        0.6      0.343\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/40      11.4G       1.27      0.977       1.47         43        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.585      0.445      0.473      0.278\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/40      11.4G      1.229     0.9231      1.441         44        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.656      0.611      0.633      0.373\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/40      11.4G      1.215     0.8929      1.423         56        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.668      0.655      0.701      0.413\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/40      11.4G      1.167     0.8495      1.387         49        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.733      0.608      0.699      0.422\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/40      11.4G      1.154     0.8248      1.384         42        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.734      0.544      0.663      0.401\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/40      11.4G      1.133     0.8009      1.368         38        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.717      0.664      0.719      0.418\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/40      11.4G      1.107     0.7664      1.346         51        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.686      0.715       0.72      0.439\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/40      11.4G      1.088     0.7475      1.337         47        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.749      0.641      0.743      0.468\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/40      11.4G      1.075     0.7307      1.322         46        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874       0.78      0.661      0.764      0.484\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/40      11.4G      1.064     0.7246      1.313         42        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.794      0.678       0.79      0.499\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/40      11.4G       1.04     0.6925      1.307         38        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.759        0.7      0.797      0.532\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/40      11.5G      1.029      0.678       1.29         39        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.835      0.771      0.852      0.561\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/40      11.4G      0.998     0.6646      1.272         83        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.902      0.783      0.881      0.549\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/40      11.4G      1.002     0.6569      1.279         46        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.764      0.777      0.832      0.533\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/40      11.4G     0.9908     0.6532      1.263         37        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.834      0.773      0.857      0.561\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/40      11.4G     0.9769       0.63      1.251         64        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.856      0.817      0.879      0.568\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/40      11.4G     0.9629     0.6127      1.242         65        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874       0.75      0.764      0.795      0.512\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/40      11.4G     0.9488     0.6013      1.237         60        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.912      0.788      0.887      0.584\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/40      11.4G     0.9372     0.5892      1.224         49        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.831      0.753      0.849      0.553\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/40      11.4G     0.9306     0.5875      1.218         54        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.904      0.831      0.912      0.611\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/40      11.4G     0.9147     0.5733      1.211         41        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.895      0.836      0.905      0.602\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/40      11.4G      0.918     0.5679      1.213         53        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.884      0.836      0.897      0.601\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      31/40      11.4G     0.9863     0.5101      1.198         29        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874        0.9      0.801      0.896      0.602\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      32/40      11.4G     0.9686     0.4898      1.187         28        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874       0.88      0.844      0.911      0.615\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      33/40      11.4G     0.9591     0.4834      1.186         20        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.916      0.806      0.893       0.59\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      34/40      11.4G     0.9472     0.4688      1.158         28        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.896      0.847       0.91       0.61\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      35/40      11.4G     0.9167     0.4609      1.157         23        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874        0.9      0.841      0.916      0.635\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      36/40      11.4G     0.9237     0.4498      1.142         27        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.915      0.843      0.919      0.622\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      37/40      11.5G     0.8989     0.4392      1.133         23        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.938      0.861      0.938      0.651\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      38/40      11.4G      0.885     0.4293      1.127         21        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.926      0.841      0.925       0.64\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      39/40      11.4G      0.876     0.4163      1.117         24        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.906      0.872      0.928      0.639\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      40/40      11.4G     0.8603     0.4097      1.108         24        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.922       0.89      0.941      0.657\n\n40 epochs completed in 2.476 hours.\nOptimizer stripped from runs/detect/yolov8_phone/weights/last.pt, 47.4MB\nOptimizer stripped from runs/detect/yolov8_phone/weights/best.pt, 47.4MB\n\nValidating runs/detect/yolov8_phone/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv8m-medium summary (fused): 157 layers, 23573169 parameters, 0 gradients, 65.4 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1773       1874      0.922       0.89      0.941      0.657\nSpeed: 0.1ms preprocess, 6.0ms inference, 0.0ms loss, 0.8ms postprocess per image\nResults saved to \u001b[1mruns/detect/yolov8_phone\u001b[0m\n💡 Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Training a Modified Model (Medium Objects)\n!yolo task=detect mode=train model=yolov8m.pt data=/kaggle/working/pandas-2-9/data.yaml  batch=-1 device=0 epochs=40 patience=50 name=yolov8_septembersa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z60okNjAwyHv","outputId":"a2ce42d5-f426-4ed3-ac21-be6b20f57d3a","execution":{"iopub.status.busy":"2024-10-28T10:45:22.134978Z","iopub.execute_input":"2024-10-28T10:45:22.135339Z","iopub.status.idle":"2024-10-28T12:00:04.818219Z","shell.execute_reply.started":"2024-10-28T10:45:22.135309Z","shell.execute_reply":"2024-10-28T12:00:04.817086Z"},"trusted":true},"outputs":[{"name":"stdout","text":"New https://pypi.org/project/ultralytics/8.3.23 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/kaggle/working/pandas-2-9/data.yaml, epochs=40, patience=50, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=yolov8_septembersa, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8_septembersa3\n2024-10-28 10:45:31.325462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-10-28 10:45:31.325522: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-10-28 10:45:31.327050: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=80 with nc=9\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3780907  ultralytics.nn.modules.head.Detect           [9, [192, 384, 576]]          \nModel summary: 295 layers, 25861531 parameters, 25861515 gradients, 79.1 GFLOPs\n\nTransferred 469/475 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8_septembersa3', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.26G reserved, 0.24G allocated, 15.39G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    25861531       79.09         0.694         28.04         48.76        (1, 3, 640, 640)                    list\n    25861531       158.2         1.034          30.2         57.03        (2, 3, 640, 640)                    list\n    25861531       316.4         2.177         52.01         92.08        (4, 3, 640, 640)                    list\n    25861531       632.7         3.647         96.36         127.5        (8, 3, 640, 640)                    list\n    25861531        1265         6.562         165.6         208.1       (16, 3, 640, 640)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 22 for CUDA:0 9.49G/15.89G (60%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/pandas-2-9/train/labels.cache... 2785 images, 75\u001b[0m\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/pandas-2-9/valid/labels.cache... 144 images, 2 bac\u001b[0m\nPlotting labels to runs/detect/yolov8_septembersa3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.000515625), 83 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/yolov8_septembersa3\u001b[0m\nStarting training for 40 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/40      10.5G      1.027      1.317      1.194         53        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323       0.92       0.97      0.971      0.774\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/40      10.7G     0.9074     0.6746      1.142         52        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.881      0.836       0.83      0.651\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/40      10.7G     0.9083     0.6686      1.144         45        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323       0.93       0.97      0.966      0.753\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/40      10.7G     0.8941     0.6185      1.142         68        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.883      0.976      0.952      0.762\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/40      10.7G     0.8534      0.576      1.113         64        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.923      0.979      0.975      0.781\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/40      10.6G     0.8262     0.5438      1.102         36        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.956      0.973      0.979      0.796\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/40      10.7G     0.8269     0.5308      1.102         60        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.962      0.978      0.978      0.802\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/40      10.7G     0.7903     0.4979      1.086         35        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.957      0.982      0.984      0.818\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/40      10.7G     0.7777     0.4996      1.083         54        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.948      0.982      0.977      0.818\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/40      10.7G       0.76     0.4734      1.064         47        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323       0.96      0.978      0.981      0.835\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/40      10.7G     0.7455     0.4589      1.061         43        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.956      0.982      0.982      0.837\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/40      10.7G      0.711     0.4399      1.047         50        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.957       0.98      0.984      0.835\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/40      10.7G     0.7113     0.4341      1.053         49        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323       0.96      0.973      0.979      0.831\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/40      10.7G     0.7091     0.4406      1.044         43        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.965      0.981      0.984      0.845\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/40      10.6G     0.6876     0.4326       1.04         56        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.958       0.98      0.978       0.85\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/40      10.6G     0.6772     0.4169      1.027         44        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323       0.95      0.984      0.978      0.841\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/40      10.7G     0.6778     0.4121      1.031         73        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.945      0.978       0.98      0.856\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/40      10.6G     0.6614     0.4056      1.023         71        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.963      0.977       0.98      0.839\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/40      10.7G     0.6523     0.3923       1.02         58        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.957      0.972      0.981       0.83\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/40      10.6G     0.6339     0.3802      1.008         49        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.963      0.967      0.982      0.829\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/40      10.6G     0.6312     0.3787      1.004         73        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.967      0.972      0.984       0.85\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/40      10.7G     0.6216     0.3803      1.007         52        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.965      0.969      0.979      0.832\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/40      10.7G     0.6152     0.3669      1.003         50        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.948      0.971      0.981      0.854\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/40      10.7G     0.6173     0.3744      1.004         50        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.953      0.973       0.98      0.849\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/40      10.7G     0.6012     0.3659     0.9973         73        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.959      0.983      0.985      0.848\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/40      10.6G     0.5808     0.3532     0.9829         56        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.958      0.981      0.977      0.842\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/40      10.7G     0.5763     0.3509     0.9879         37        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.962      0.974      0.984      0.851\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/40      10.7G     0.5585     0.3368     0.9744         69        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.955      0.982      0.978      0.854\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/40      10.7G     0.5626     0.3276     0.9801         34        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.956      0.982      0.984       0.86\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      31/40      10.7G     0.4839     0.2909     0.9572         28        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.947      0.988      0.981      0.854\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      32/40      10.7G     0.4813      0.284     0.9528         30        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.955       0.98       0.98      0.843\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      33/40      10.7G     0.4591     0.2729     0.9396         30        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.955       0.98      0.983      0.851\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      34/40      10.7G     0.4482      0.261      0.939         30        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.953      0.986      0.979      0.851\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      35/40      10.7G     0.4394     0.2557      0.933         41        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.944      0.985      0.983      0.857\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      36/40      10.6G     0.4287     0.2467     0.9284         21        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.956      0.978      0.984      0.862\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      37/40      10.7G     0.4178     0.2425     0.9238         35        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.954      0.976      0.983       0.86\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      38/40      10.7G     0.4105     0.2401     0.9231         25        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323      0.954      0.975      0.983      0.862\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      39/40      10.6G     0.4038      0.233     0.9107         33        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323       0.95       0.98      0.984      0.863\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      40/40      10.7G     0.3925     0.2236     0.9114         24        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323       0.94      0.986      0.982      0.859\n\n40 epochs completed in 1.234 hours.\nOptimizer stripped from runs/detect/yolov8_septembersa3/weights/last.pt, 52.0MB\nOptimizer stripped from runs/detect/yolov8_septembersa3/weights/best.pt, 52.0MB\n\nValidating runs/detect/yolov8_septembersa3/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 218 layers, 25844971 parameters, 0 gradients, 78.7 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        323       0.95       0.98      0.984      0.864\n      chopped tomatoes        144         41      0.953      0.999      0.994      0.899\n     dishwasing liquid        144         29      0.923          1       0.99      0.866\n         foul medammes        144         42      0.955          1      0.991      0.922\nglass cleaner lavender        144         34      0.971      0.978      0.994      0.849\n    glass cleaner lime        144         37      0.943          1      0.994      0.856\n     sweet corn kernel        144         22      0.874      0.943      0.954       0.88\n                tahina        144         56      0.965      0.982      0.987      0.821\n        tomato ketchup        144         29      0.965      0.954      0.968      0.748\n           white beans        144         33          1      0.968      0.981      0.936\nSpeed: 0.2ms preprocess, 11.6ms inference, 0.0ms loss, 11.9ms postprocess per image\nResults saved to \u001b[1mruns/detect/yolov8_septembersa3\u001b[0m\n💡 Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Modified YOLOv8 Architecture for Big Objects","metadata":{"id":"ZzfgRXZNwyS7"}},{"cell_type":"code","source":"# Copy YOLOv8l Big Architecture\n!cp yolov8.yaml yolov8l-big.yaml","metadata":{"id":"rFnHIJw_HPS3"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div>\n  <img src=\"https://www.stunningvisionai.com/course/yolov8-architecture-modification-for-big-object.png\" height=\"685\"/>\n</div>","metadata":{"id":"tzEzGrcjHZA1"}},{"cell_type":"markdown","source":"<div>\n  <img src=\"https://www.stunningvisionai.com/course/yolov8-architecture-for-big-object.png\" height=\"720\"/>\n</div>","metadata":{"id":"QXFYn2DFHZOl"}},{"cell_type":"markdown","source":"### Download the dataset","metadata":{"id":"ofNh1Jpe0q-b"}},{"cell_type":"code","source":"# Go to the data folder\n%cd data","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBeQjhgTcAie","outputId":"f453182f-c6a0-460d-d56b-47924c910322"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download the dataset\n!gdown https://drive.google.com/uc?id=1FW0QR0jITbhLiHL_B5HqYrowQtoQukFX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsFyyiQUw0Z9","outputId":"d1efd5df-3bea-4b32-da2d-eb8d27e3eff6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unzip Dataset\n!unzip tomato_leaf_dataset.zip","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SykjMcN7b_vc","outputId":"9150ecb0-e0c1-4f08-dd26-d62d49ed94cd"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Download the data file","metadata":{"id":"rjjkbgjY007T"}},{"cell_type":"code","source":"# Download the data file\n!gdown https://drive.google.com/uc?id=1Q50HdUtbLscs03I2HFm5r4Ah0gWHS5Kd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvrOkg6Sb_yI","outputId":"7aabd2c4-0668-4bb2-ee5a-f31b7262a3bf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Go to the root folder\n%cd ../","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gixdfILIb_1M","outputId":"e155d76f-8973-4ad5-ced8-2e24c81f52e3"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training","metadata":{"id":"SM90OCFz1Gpt"}},{"cell_type":"code","source":"# Training Original Model\n!yolo detect train model=yolov8l.yaml data=data/tomato_leaf.yaml workers=2 batch=12 device=0 epochs=100 patience=50 name=yolov8_tomato_leaf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6B7nAnYgb_3Y","outputId":"f76d02df-8fd0-41ab-da5e-7012e8ebd182"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training a Modified Model (Big Objects)","metadata":{"id":"ltDXbk311KS9"}},{"cell_type":"markdown","source":"# YOLOv8 for big objects with TensorRT","metadata":{"id":"chpSujqjwrDp"}},{"cell_type":"code","source":"!pip install tensorrt==8.6.1 tensorrt_lean==8.6.1 tensorrt_dispatch==8.6.1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2J9d50-zw5OC","outputId":"aadbc847-ce79-44fc-c78c-b980e514a8e4","execution":{"iopub.status.busy":"2024-07-14T23:20:06.159429Z","iopub.execute_input":"2024-07-14T23:20:06.159832Z","iopub.status.idle":"2024-07-14T23:22:43.925849Z","shell.execute_reply.started":"2024-07-14T23:20:06.159797Z","shell.execute_reply":"2024-07-14T23:22:43.924627Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting tensorrt==8.6.1\n  Downloading tensorrt-8.6.1.tar.gz (16 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tensorrt_lean==8.6.1\n  Downloading tensorrt_lean-8.6.1.tar.gz (16 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tensorrt_dispatch==8.6.1\n  Downloading tensorrt_dispatch-8.6.1.tar.gz (16 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_lean, tensorrt_dispatch\n  Building wheel for tensorrt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tensorrt: filename=tensorrt-8.6.1-py2.py3-none-any.whl size=16971 sha256=f900a78aa3c570c53e3658528eb22ff7c521c1fadbf5c4a8567333aa586b51a2\n  Stored in directory: /root/.cache/pip/wheels/6d/29/56/abdffd4c604f255b5254bef3f1c598ab7811ea020540599438\n  Building wheel for tensorrt_lean (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tensorrt_lean: filename=tensorrt_lean-8.6.1-py2.py3-none-any.whl size=17053 sha256=17a36a7e4b3aeb019c181057786c2cb1b7feee190f7dfcff0939aa19793d695f\n  Stored in directory: /root/.cache/pip/wheels/c9/e7/d5/6397d8f9cb33a20787497416f27ac8db4f847c6ab810f28717\n  Building wheel for tensorrt_dispatch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tensorrt_dispatch: filename=tensorrt_dispatch-8.6.1-py2.py3-none-any.whl size=17124 sha256=e8c4e887d92f7c9afaf4a04b48c60069295be4d585a348803aef298d91a45c0d\n  Stored in directory: /root/.cache/pip/wheels/44/57/7a/546a598e72b22868df0166b1951ffb0b1ad6d69c9d3ce962cd\nSuccessfully built tensorrt tensorrt_lean tensorrt_dispatch\nInstalling collected packages: tensorrt_lean, tensorrt_dispatch, tensorrt\nSuccessfully installed tensorrt-8.6.1 tensorrt_dispatch-8.6.1 tensorrt_lean-8.6.1\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!pip install onnx==1.14.1 onnxsim==0.4.33 onnxruntime-gpu==1.16.1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GVvx7YYSw_rs","outputId":"6215ab71-67b4-4597-fc11-856afb439608","execution":{"iopub.status.busy":"2024-07-14T23:23:42.960068Z","iopub.execute_input":"2024-07-14T23:23:42.960952Z","iopub.status.idle":"2024-07-14T23:25:05.546517Z","shell.execute_reply.started":"2024-07-14T23:23:42.960914Z","shell.execute_reply":"2024-07-14T23:25:05.545365Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting onnx==1.14.1\n  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\nCollecting onnxsim==0.4.33\n  Downloading onnxsim-0.4.33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nCollecting onnxruntime-gpu==1.16.1\n  Downloading onnxruntime_gpu-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from onnx==1.14.1) (1.26.4)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx==1.14.1) (3.20.3)\nRequirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.10/site-packages (from onnx==1.14.1) (4.9.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from onnxsim==0.4.33) (13.7.0)\nCollecting coloredlogs (from onnxruntime-gpu==1.16.1)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu==1.16.1) (23.5.26)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu==1.16.1) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu==1.16.1) (1.13.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu==1.16.1)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime-gpu==1.16.1) (3.1.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->onnxsim==0.4.33) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->onnxsim==0.4.33) (2.17.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime-gpu==1.16.1) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->onnxsim==0.4.33) (0.1.2)\nDownloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading onnxsim-0.4.33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading onnxruntime_gpu-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxsim, onnxruntime-gpu\n  Attempting uninstall: onnx\n    Found existing installation: onnx 1.16.1\n    Uninstalling onnx-1.16.1:\n      Successfully uninstalled onnx-1.16.1\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.14.1 onnxruntime-gpu-1.16.1 onnxsim-0.4.33\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Convert the Model\n","metadata":{"id":"3nDNC2cixE9B"}},{"cell_type":"code","source":"# Export YOLOv8 Model to Tensorrt\n!yolo export model=/kaggle/working/yolov8-architecture/runs/detect/yolov8_inveep2/weights/best.pt format=engine half=True device=0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_xmtWyCxIOh","outputId":"ba4b6bec-18d6-4151-ef27-4d9433037d0a","execution":{"iopub.status.busy":"2024-07-14T23:25:16.704952Z","iopub.execute_input":"2024-07-14T23:25:16.705367Z","iopub.status.idle":"2024-07-14T23:29:36.845784Z","shell.execute_reply.started":"2024-07-14T23:25:16.705333Z","shell.execute_reply":"2024-07-14T23:29:36.844436Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv8m-medium summary (fused): 197 layers, 53132640 parameters, 0 gradients, 149.8 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/kaggle/working/yolov8-architecture/runs/detect/yolov8_inveep2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 20, 1600) (101.6 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.33...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 5.1s, saved as '/kaggle/working/yolov8-architecture/runs/detect/yolov8_inveep2/weights/best.onnx' (101.4 MB)\n\n\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.6.1...\n[07/14/2024-23:25:31] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 718, GPU 1010 (MiB)\n[07/14/2024-23:25:37] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +248, GPU +48, now: CPU 1042, GPU 1058 (MiB)\n[07/14/2024-23:25:37] [TRT] [I] ----------------------------------------------------------------\n[07/14/2024-23:25:37] [TRT] [I] Input filename:   /kaggle/working/yolov8-architecture/runs/detect/yolov8_inveep2/weights/best.onnx\n[07/14/2024-23:25:37] [TRT] [I] ONNX IR version:  0.0.8\n[07/14/2024-23:25:37] [TRT] [I] Opset version:    17\n[07/14/2024-23:25:37] [TRT] [I] Producer name:    pytorch\n[07/14/2024-23:25:37] [TRT] [I] Producer version: 2.1.2\n[07/14/2024-23:25:37] [TRT] [I] Domain:           \n[07/14/2024-23:25:37] [TRT] [I] Model version:    0\n[07/14/2024-23:25:37] [TRT] [I] Doc string:       \n[07/14/2024-23:25:37] [TRT] [I] ----------------------------------------------------------------\n[07/14/2024-23:25:37] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.HALF\n\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 20, 1600) DataType.HALF\n\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as /kaggle/working/yolov8-architecture/runs/detect/yolov8_inveep2/weights/best.engine\n[07/14/2024-23:25:37] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n[07/14/2024-23:25:37] [TRT] [I] Graph optimization time: 0.0483701 seconds.\n[07/14/2024-23:25:37] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n[07/14/2024-23:25:37] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n[07/14/2024-23:29:34] [TRT] [I] Detected 1 inputs and 3 output network tensors.\n[07/14/2024-23:29:35] [TRT] [I] Total Host Persistent Memory: 256736\n[07/14/2024-23:29:35] [TRT] [I] Total Device Persistent Memory: 1264640\n[07/14/2024-23:29:35] [TRT] [I] Total Scratch Memory: 0\n[07/14/2024-23:29:35] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 45 MiB, GPU 218 MiB\n[07/14/2024-23:29:35] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 156 steps to complete.\n[07/14/2024-23:29:35] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 8.14678ms to assign 10 blocks to 156 nodes requiring 48332800 bytes.\n[07/14/2024-23:29:35] [TRT] [I] Total Activation Memory: 48332800\n[07/14/2024-23:29:35] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +9, GPU +156, now: CPU 9, GPU 156 (MiB)\n\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 249.5s, saved as '/kaggle/working/yolov8-architecture/runs/detect/yolov8_inveep2/weights/best.engine' (155.5 MB)\n\nExport complete (251.1s)\nResults saved to \u001b[1m/kaggle/working/yolov8-architecture/runs/detect/yolov8_inveep2/weights\u001b[0m\nPredict:         yolo predict task=detect model=/kaggle/working/yolov8-architecture/runs/detect/yolov8_inveep2/weights/best.engine imgsz=640 half \nValidate:        yolo val task=detect model=/kaggle/working/yolov8-architecture/runs/detect/yolov8_inveep2/weights/best.engine imgsz=640 data=/kaggle/working/yolov8-architecture/inveep_sale-15/data.yaml half \nVisualize:       https://netron.app\n💡 Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))\n","metadata":{"execution":{"iopub.status.busy":"2025-04-24T22:39:31.507423Z","iopub.execute_input":"2025-04-24T22:39:31.507898Z","iopub.status.idle":"2025-04-24T22:39:31.514337Z","shell.execute_reply.started":"2025-04-24T22:39:31.507857Z","shell.execute_reply":"2025-04-24T22:39:31.513400Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"download_file('/kaggle/working/yolov8-architecture/runs/detect/yolov8_phone/weights/best.pt', 'phone')\n","metadata":{"execution":{"iopub.status.busy":"2025-04-24T22:40:35.358932Z","iopub.execute_input":"2025-04-24T22:40:35.359585Z","iopub.status.idle":"2025-04-24T22:40:37.477213Z","shell.execute_reply.started":"2025-04-24T22:40:35.359559Z","shell.execute_reply":"2025-04-24T22:40:37.476336Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"/kaggle/working/phone.zip","text/html":"<a href='phone.zip' target='_blank'>phone.zip</a><br>"},"metadata":{}}],"execution_count":16}]}